{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"colab":{"name":"Data Preparation .ipynb","provenance":[],"toc_visible":true,"machine_shape":"hm"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"P9JSRX7gtUxD","colab_type":"code","outputId":"7768eb00-17eb-4699-e8db-08abbb4bbffa","executionInfo":{"status":"ok","timestamp":1577295620274,"user_tz":-60,"elapsed":1382,"user":{"displayName":"MOHAMED BOUZIANE","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAuxZzJIQTWk1prEgdgK2S6RQNWZGpgOHOjk8dHlg=s64","userId":"00795055450802678161"}},"colab":{"base_uri":"https://localhost:8080/","height":55}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Xrr2e5cQtO0h","colab_type":"code","outputId":"eb23f254-beb0-4657-839c-a5d5518f9f03","executionInfo":{"status":"ok","timestamp":1577295805439,"user_tz":-60,"elapsed":181048,"user":{"displayName":"MOHAMED BOUZIANE","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAuxZzJIQTWk1prEgdgK2S6RQNWZGpgOHOjk8dHlg=s64","userId":"00795055450802678161"}},"colab":{"base_uri":"https://localhost:8080/","height":89}},"source":["\n","import string\n","import re\n"," \n","# load file into memory\n","def load_file(file):    \n","    file = open(file, 'r')  # open the file as read only\n","    text = file.read()    # read all text\n","    file.close()    # close the file\n","    return text\n"," \n","    \n","    \n","# clean  text\n","def clean_text(file):   \n","    tokens = re.split('\\n|OR|AND| ',file)     # split into tokens by white space   \n","    table = str.maketrans('', '', string.punctuation)   # remove punctuation from each token\n","    tokens = [w.translate(table) for w in tokens]    \n","    tokens = [word for word in tokens if word.isalpha()]    # remove remaining tokens that are not alphabetic   \n","    tokens = [word.lower() for word in tokens]     # make lower case\n","    return tokens\n"," \n","    \n","    \n","# save tokens to file, per line\n","def save_file(lines, file):\n","    data = '\\n'.join(lines)\n","    file = open(file, 'w')\n","    file.write(data)\n","    file.close()\n"," \n","\n","\n","\n","\n","# load document\n","filename = '/content/drive/My Drive/Colab Notebooks/search_query/searchterms.txt'\n","txt = load_file(filename)\n","    \n","    \n","    \n","# clean document\n","tokens = clean_text(txt)\n","print(tokens[:200])\n","print('Total Tokens: %d' % len(tokens))\n","print('Unique Tokens: %d' % len(set(tokens)))\n"," \n","    \n","    \n","    \n","# # organize into sequences of tokens\n","# length = 50 + 1\n","# sequences = list()\n","# for i in range(length, len(tokens)):\n","#     seq = tokens[i-length:i]   # select sequence of tokens\n","#     line = ' '.join(seq)    # convert into a line\n","#     sequences.append(line)   # store\n","# print('Total Sequences: %d' % len(sequences))\n"," \n","    \n","    \n","# # save sequences to file\n","# out_file = 'searchterms_sequences.txt'\n","# save_file(sequences, out_file)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["['q', 'u', 'e', 'r', 'y', 'a', 'r', 'c', 'h', 'i', 't', 'e', 'c', 't', 'r', 'e', 'n', 'o', 'v', 'a', 't', 'i', 'o', 'n', 'c', 'a', 'd', 'm', 'o', 'd', 'e', 'l', 'm', 'o', 'd', 'e', 'l', 'i', 'n', 'g', 'm', 'o', 'd', 'e', 'l', 'e', 'r', 'n', 'o', 't', 's', 'o', 'u', 'n', 'd', 'd', 'e', 'v', 'e', 'l', 'o', 'p', 'e', 'r', 'i', 'n', 't', 'e', 'r', 'a', 'c', 't', 'i', 'o', 'n', 'i', 'n', 't', 'e', 'r', 'f', 'a', 'c', 'e', 's', 'o', 'l', 'u', 't', 'i', 'o', 'n', 'c', 'l', 'o', 'u', 'd', 'b', 'i', 'm', 'a', 'u', 't', 'o', 'c', 'a', 'd', 'a', 'r', 'c', 'h', 'i', 't', 'e', 'c', 't', 'u', 'r', 'a', 'l', 'b', 'u', 'i', 'l', 'd', 'i', 'n', 'g', 'i', 'n', 'f', 'o', 'r', 'm', 'a', 't', 'i', 'o', 'n', 'm', 'o', 'd', 'e', 'l', 'i', 'n', 'g', 'b', 'i', 'm', 'm', 'a', 'n', 'a', 'g', 'e', 'r', 'b', 'i', 'm', 'c', 'o', 'o', 'r', 'd', 'i', 'n', 'a', 't', 'o', 'r', 'b', 'i', 'm', 'm', 'o', 'd', 'e', 'l', 'e', 'r', 'c', 'a', 'd', 'd', 'r', 'a', 'f', 't', 'e', 'r', 'd', 'e', 's', 'i', 'g', 'n', 'e', 'r', 'd']\n","Total Tokens: 277938874\n","Unique Tokens: 475\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nJ5H-19uuxfC","colab_type":"code","colab":{}},"source":["all_tokens = str()\n","for i in tokens:\n","    all_tokens+= ' ' + i\n","\n","\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FP4-oPcJ_UxC","colab_type":"code","colab":{}},"source":["def save_file(data, file):\n","    \n","    file = open(file, 'w')\n","    file.write(data)\n","    file.close()\n","\n","\n","\n","out_file = '/content/drive/My Drive/Colab Notebooks/search_query/searchterms_sequences.txt'\n","save_file(all_tokens, out_file)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"w0OTLpJO_mC2","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}